# 質問
全体のこと
①データ分析で数学の計算方法や計算手順を理解する必要があるのか。また、どこまで理解すれば良いのか

・やっていることは何をしているかを把握するため、計算手順や計算方法はある程度公式を説明する
要は、実際の計算はいらないが、他は知識が必要
微分を持つ理由を使う時の理由。

②データ分析【WEBの販売系】をしていく際、どの数学の知識が必要になるのか。また、どの数学は覚えなくていいか

損益分益点＝赤字と黒字の境目
微分と積分は必須。なぜ微分がいるのかを必要。
微分は、上がり幅や下がり幅の時に使用。
将来的にどのぐらい上がり幅や下がり幅があるのかを調べる。
※平均値からはみ出たものをノイズとみなす

線形代数＝データ分析はあまり、線形代数出てこない。頻度は少ない
確率＝データ分析した結果、集計したときに使う。　相関しているのかしていないのか。
　　　※データ分析ではない。

回帰分析＝将来的に予測値を立てるために回帰分析をつる
　　　　　※回帰は使わない


「FXで使うアルゴリズム」
「クラスタリングの考え方は一度高い」



各数学の疑問点
①微分で、傾きを出すことはわかったが、なぜ機械学習をする上で微分が必要になるのかがわからない。


②
行列は、ベクトルを変換する機能を持ちます。例えば以下のように、ベクトルに行列を掛け合わせることで、異なるベクトルに変わります。というのがわからないです。
https://terakoya.sejuku.net/programs/104/chapters/1316


③ゼロ行列・単位行列・逆行列はいつ使うのか？あとそれぞれの意味がわからないです。

画像認識で使う

スラカーバイ＝重みをつける時に使用
重み＝男性女性３割７割だとしたら
一斉にアンケートした場合（男女不明）、男性３０％をかけとくと信頼できる

ゼロ行列＝ゴミデータを存在にする場合にしよう

単位行列＝重みをいらない場合に使用


④分散を使用するケースはあるのか？標準偏差の方が良くないのか。。。



⑦ニューラルネットワークと重回帰の違いがわからないです。

基本同じ。
ニューラールネットワーうは人間の頭脳に近い。
人間に代わりになるときは、ニューラルネットワークを使用する

⑧予測モデルの性能評価には、正解率・再現率・特異度・適合率・F値などの指標は、実際どんな場面で使用されるのかを知りたいです。

# setumei
▪️機械学習とは
法則やルールに従って、予測や判断をすること

例：部屋の広さから、家賃を予測したいという課題があったとする
その場合、部屋の広さと家賃がセットになっている大量のデータを利用して、両者の関係性のルールを見つけます。
このルールを予測モデルと呼びます。
そこで、家賃の予測が可能となる

▪️機械学習の流れ

１。データをプロットする
※プロットとは、データや図やグラフ上に示すこと。
２。プロットされた点にできるだけ沿った直線を引く
※予測モデルを考える「直線」「曲線」など
　　└データの関係性を考えるパート
３。直線とプロットされた点の誤差を測定し、誤差が最小になるように直線を調子する
４。調整済みの直線に基づいて家賃を予測する


▪️機械学習の数学が活用されているところ
以下３つポイントで数学と統計学が使用されている

①誤差が最小になるように直線を調整するステップ
「微分」という数学の考え方で、誤差が最小となる直線を決定している

②データをプロットし、直線をひき、予測モデルを構築する手法
このモデル構築の方法論は、線形回帰（確率・統計）と呼ばれる手法です。

③データの取り扱い
例えば、家賃を予測する場合、駅からの距離や広さ、築年数などの複数の要素が家賃に影響を与えます。
この多数の要素をひとかたまりのデータとして取り扱う技術が必要になる。この複数の数値要素をまとめるのを「（線形代数）ベクトル」という概念を扱う。

# 微分
▪️微分とは
グラフに接する直線の傾きを求める手法のこと
要は予測モデルを構築することにリイ要される流れ

▪️微分のメリット
微分によって、曲線の接戦の傾きがわかると、ｙ軸の極大もしくは極小となる位置を見つける手掛かりとなる。
※極大と極小とは、、、前後の一定範囲においての1番大きい数値と小さい数値です。そのため、グラフ内の最大、最小ではありません。

▪️機械学習の流れ
部屋の広さから家賃を予測するという事例

１。データをプロットする
前提として、「家賃」と「部屋の広さ」のデータがある

部屋の広さをｘとして
家賃をｙとする

２。プロットされた点にできるだけ沿った直線を引く

今回の予測モデルは「直線（y=ax+b）」とする

３。直線とプロットされた点の誤差を測定し、誤差が最小になるように直線を調子する

直線に数値を入れて、誤差を出す作業。
各データの誤差を2乗（マイナスもプラスに切り替えるから）したものをすべて足して、なるべく和を少なくする
そこで、aとｂを出す

４。調整済みの直線に基づいて家賃を予測する

3で求めたaとbをy=ax+bに入れて、予測モデルの完成。

▪️傾きの求め方
主に流れは以下の通りです。

1.少しだけ距離の離れた２点間の傾きを計算する
２。徐々に距離を縮めて傾きを算出すること

# 線形代数
▪️ベクトル
複数の要素を人まとまりに表現できる

▪️行列


# 確率
▪️分散
平均値からのばらつき具合を表現する
データが平均値から散らばっていると、分散が大きい
データが平均値付近にいると分散が小さい

▪️標準偏差　※分散よりもおすすめ
分散と同様に平均値からのばらつき具合を調べる指標
分散の正の平方根を計算すると標準偏差が出る。

分散は、平均の差を2乗しているので、感覚的に平均値との距離感が掴めないというデメリットがあります。
そのため、そのデメリットを克服するために、標準偏差を使用する
要は各データの平均値との距離感を掴みやすくなる。

▪️相関関数
相関の度合いを−１から１までの数値で表現したもの
一方が増加すると他方も増加する場合は、相関係数は正となる。
反対に一方が増加すると、他方が減少すると相関係数は負となる

※注意として、相関があるから＝必ずしも因果関係があるとは限らないので、自分の考えが必要であり注意が必要

▪️確率密度関数
関数が描く曲線と横軸で挟まれた領域の面積によって、確率を示す関数のこと

▪️正規分布
以下の特徴を持った確率分布

・最も高い位置が平均値
・平均値を中心に左右対称である
・標準偏差が大きくなると、正規分布の確率密度関数はなだらかな山の形になる
・標準偏差が小さくなると、正規分布の確率密度関数は急な山の形を描く

▪️期待値
あるものごとを行うときに見込まれる値

# 統計学（回帰）
前提として、機械学習を実装する過程で、実装者本人が状況に応じて判断するポイントがあります；。
例えば、予測モデルの選択やモデルの設定値の算出方針などです。

その中の予測モデルの仕組みや構築は統計学が用いられているので、ちゃんと理解しましょう

▪️回帰
数値データを予測する手法のこと。
例：身長や体重、金額など、、、

▪️回帰を使うシーンの例
。気温や降水量、季節、曜日、立地などから店舗の売上を予測する
・スポーツの試合や対戦チームや開催場所、出場メンバー、天候などから試合の観客数を予測

▪️回帰の流れ
以下の流れで実施される

１。予測モデルを選ぶ
２。予測モデルのパラメータを推定する
３。予測モデルの性能を評価

以下から説明
１。予測モデルを選ぶ
最初のステップは、予測モデルの選択。
予測モデルとは、データから見つけ出すルールや法則のことである。

前の章だと、y=0.512x-1.71　という数しきが予測モデルに該当

このステップで選択するのは、予測モデルの構造
今回は、「y=ax+b」で表せる直線である。
aとbは、パラメータと呼ばれる特定の数値です。パラメータを変化させることで直線の傾きや位置が変わる
部屋の広さだけなので、上記モデルを選ぶ。
もし、部屋の広さ以外にも駅の近さなど、複数になったらモデル構造を変えていく

２。予測モデルのパラメータを推定する

パラメーターを調整して、今あるデータにフィットするように調整をする。

最適なパラメータを求める方針は、いか２点です。

・予測モデルが算出する予測値
・データの差
が小さくなるようにaとbを推定する。
この推定手法でよく使うのは「最小二乗法」だす
※先ほどの章で計算したやつです。差を２乗にしてすべて足すやつで、その和を少なくすることが重要


３。予測モデルの性能を評価
過学習が発生していないかをチェックすること。
データにフィットするために複雑なモデルにしたり、データ量が少ないと過学習が発生し、良い評価がされない可能性がある。

この過学習をしているかチェックするためには、手元のデータを２つに分けて異なる用途に利用するのが良い。
１つ目は、「学習データ」と呼ばれる予測モデルのパラメータ推定をするためのデータ
２つ目は、「テストデータ」と呼ばれる予測モデル完成後に性能をテストするためのデータ
テストデータをまるで未知のデータのように利用し、予測モデルがどの程度の制度を持つかをチェックする

回帰では、予測モデルの性能評価に決定係数と呼ばれる指標をよく利用する

▪️決定係数
データに対する予測モデルのフィット度合いを数値かした指標のこと
１以下の数値で表され、大きいほど綺麗に当てはまっているということ。

▪️コンピュータが担う部分と人間が担う部分

１。予測モデルを選ぶこと
実装者本人が、解決したい課題や目的によって適切なモデルを選択する

２。予測モデルのパラメータ推定。
実装者本人は、目的関数（予測値と実装の値の誤差）を最小化する手法を選択
PCは、主に微分によるパラメータ計算の部分を担う
また、モデルによるが、実装者本人が調整すべき設定値が存在する。これが、ハイパーパラメーター
である。

３。予測モデルの性能を評価する。
 PCは、決定係数の算出を行う。
 実装者本人は、算出された決定係数から問題なしとするか回帰をやり直すかの判断を行う

▪️予測モデルの種類（回帰）
・単回帰
１つの要素から数値を予測するモデル
例；部屋の広さから家賃を予測するケースなど、、、

・重回帰
複数の要素から数値を予測するモデル

例：
部屋の広さと駅からの距離
築年数

上記のように２つ以上の要素から家賃を予測する場合、重回帰を利用する。

・ニューラルネットワーク
中間層と呼ばれる領域での計算プロセるをはさんで予測をするモデル。
中間層で計算過程を挟むため、予測値の計算式が複雑になりますが、複雑であればあるほど、予測モデルの表現力が高まる。
ただ、その中間層のノードが何を意味するかわからないので、予測根拠を説明しづらいというデメリットもある。
※中間層の数は、実装者本人が自由に調整可能

ちなみに重回帰と一緒で、複数の要素から数値を予測する際に利用。

・Ridgh回帰、Lasso回帰
過学習を防ぐために工夫された回帰モデル。
過学習が起きる要因に「重み」が大きくなりすぎることがある。
その重みを大きくならないようにするのが、このモデル

ちなみにRidgh回帰は、重みの２乗わに制約を貸している
Lasso回帰は、重みの絶対値の和に制約を課している


・サポートベクター回帰（SVR）
一定の値より小さな誤差は無視する予測モデルのこと。
モデル周辺に一定の範囲以内にある数値を誤差０とすること。
これをイプシロン感度損失という

ちなみにノイズに強いモデルと呼ばれ、重みに制約をかすので、過学習を防ぐ仕組みもある。